---
Title: Usability Test Considerations
Category: Reading
Author: Joshua Robinson
Phase: studio-1
Time: 
Mastery: 
Updated: 08-17-2021
Concepts: 
---
Curriculum: #reading #studio-1 
Target skills: 
Target objective:

# Usability Test Considerations
> If the user can’t use it, it doesn’t work. 
> —Susan Dray, Usability Professionals’ Association

Usability testing focuses on testing the ease of use and understanding of a design. And, at its most distilled, it aims to answer the question: Can the user complete this task—yes or no? Since it’s more focused on the testing task and flow completion. It typically requires a comprehensive design, either an interactive prototype or a developed product, that provides more definition around interaction and content. Depending on the product’s level of fidelity, usability testing can generate quantitative results with the help of online testing software or more qualitative results through user interviews. 

Some areas you might focus on for usability testing:
-   Guidance and navigation: Gauge whether users understand how they can interact and navigate throughout a design. (ex. Walk me through how you would complete the “x” task. What on this screen do you think you can interact with? Why?)
-   Efficiency: Analyze how long it takes users to complete specific tasks and identify areas for improvement. (ex. I noticed you paused during “x”. Why was that?”
-   Features and functionality: Assess how useful certain features and functions of a design are. (ex. When do you typically use the “x” feature? How often would you say that is?)
-   Visual communication: Assess how well the visual design supports the user experience by establishing content relationships, hierarchy, and points of interest. (ex. What content and elements do you think is related to each other on this screen? Why?)
## Usability testing can take place any time
Usability evaluation can technically happen at any point in the product development or design lifecycle. If done early in the life cycle, evaluations like competitive analysis (focused on usability) or heuristic evaluations can be beneficial. If later in the product’s life cycle, testing and evaluations are commonly done when the product is live leveraging digital tracking tools or user interviews. By watching real users or customers attempt realistic tasks within the product, qualitative and quantitative insights into the product’s usability can be gathered. These insights can then inform decisions on how the product can be improved and advanced over time.
## Possible evaluation criteria
Task scenarios are a great tool to conduct usability testing with users, but that is only one part of the puzzle. [Usability.gov](http://www.usability.gov/how-to-and-tools/methods/planning-usability-testing.html) provides some other metrics and types of data worth evaluating:
-   Successful Task Completion: How successful are users in completing the task at hand? Designers should capture this data quantitatively, assigning a value to the users’ success. It may also be worthwhile to capture feedback from the user and self-evaluate how successful they were in accomplishing the task.
-   Critical Errors: Record when and where users deviate from accomplishing the goal of the scenario. Typically these errors will prevent the user from completing the task successfully. 
-   Non-Critical Errors: When users commit errors in the intended workflow but can recover and complete the task anyway. This may help designers understand the ‘less happy’ paths that users take and why that may happen.
-   Error-Free Rate: Inverse to the aforementioned critical errors, how many users complete the task without committing any mistakes.
-   Time On Task:  How long does the user spend on each task before completion or reaching a critical error.
-   Subjective Measures: Post-task or post-test questions gauge users’ self-ratings for ease of use, satisfaction, or finding information. Typically these are 5-7 point Likert Scale questions.
-   Likes, Dislikes, and Recommendations: Users’ feedback on what they liked most, least, and any recommendations they have.
## How many users should you include?
With a solid idea of what to ask users to do and what type of data will be captured, how do designers know how much data is enough? According to the [Nielsen Norman Group](https://www.nngroup.com/articles/how-many-test-users/), it will depend on the type of testing conducted. 
-   **Usability Tests** 
    Five user tests generally allow designers to uncover many, including the most severe usability issues. More than five can result in diminishing returns for the effort of conducting testing.
-   **Quantitative Studies**  
    Twenty users is the minimum number to meet any statistically significant threshold. Of course, a higher degree of confidence can be achieved with more users.
-   **Card Sorting**  
    Fifteen users at a minimum.
-   **Eye Tracking**  
    Thirty-nine users minimally to produce stable heat maps.

There are also Office of Management and Budget (OMB) guidelines for those working in the federal sector, which are guidelines tied to the [Paperwork Reduction Act for usability testing](https://www.usability.gov/how-to-and-tools/guidance/pra-overview.html).

---
# Quiz
Choose the correct answer: 
1. User is prevented from completing the task.
	1. Time on task
	2. Subjective measure
	3. Non-critical error
	4. Critical error (correct)
	5. None of these
2. Follow-up questionnaire on satisfaction with task.
	1. Time on task
	2. Subjective measure (correct)
	3. Non-critical error
	4. Critical error
	5. None of these
3. 80% of users completed the task successfully. 
	1. Time on task
	2. Subjective measure
	3. Non-critical error
	4. Critical error 
	5. None of these (correct, it's Error-free rate)
4. Needs at least twenty users to meet any statistically significant threshold. 
	1. Eye tracking
	2. Card sorting
	3. Usability tests
	4. Quantitative studies (correct)
	5. All of the above
5. Likely to see the same errors over and over after about five users.
	1. Eye tracking
	2. Card sorting
	3. Usability tests (correct)
	4. Quantitative studies 
	5. All of the above