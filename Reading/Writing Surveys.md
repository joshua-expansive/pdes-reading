---
Title: Surveys—Writing Effective Questions
Category: Reading
Author: Joshua Robinson 	
Phase: 1
Time: 
Mastery level: 
Date created: 05-24-2021
Concepts: surveys
---
Curriculum: #process-UX #reading 
Skills: #research #survey-writing 

# Surveys
When you write survey questions, you are designing the experience for the person taking the survey. So take reasonable care in how you write survey questions. Your goal is to write questions that are 1) easy to read, 2) free of bias, and 3) answered accurately. **Always pre-test your survey questions to evaluate how people respond.** 

Decide what topics you will cover in your survey. Collaborate and discuss these topics with others. Each topic and the related question should have a justification for being included. 

---
## Questions can be open-ended or closed-ended. 
Open-ended questions require more effort and time to answer by asking users to write answers in a text box. Asking too many of them may result in lower participation. Use open-ended questions when you want participants to provide context, inner thinking, or experience. 

Closed questions can yield quantitative or qualitative data. They’re faster to answer since participants do not need to provide specific details or context supporting their responses. Instead, they choose from a list of answers using checkboxes, radio buttons, or rating scales. 

You can re-write many open-ended questions as close-ended questions. Consider [this insight from Pew Research](https://www.pewresearch.org/methods/u-s-survey-research/questionnaire-design/) about a survey poll question. 

 > ...in a poll conducted after the presidential election in 2008, people responded very differently to two versions of this question: “What one issue mattered most to you in deciding how you voted for president?” One was closed-ended and the other open-ended. In the closed-ended version, respondents were provided five options (and could volunteer an option not on the list).
>
> When explicitly offered the economy as a response, more than half of respondents (58%) chose this answer; only 35% of those who responded to the open-ended version volunteered the economy. Moreover, among those asked the closed-ended version, fewer than one-in-ten (8%) provided a response other than the five they were read; by contrast fully 43% of those asked the open-ended version provided a response not listed in the closed-ended version of the question. All of the other issues were chosen at least slightly more often when explicitly offered in the closed-ended version than in the open-ended version.

Pew Research often runs pilot studies with open-ended questions to discover the most common answers. Then they develop close-ended questions based on the results from the study. A product designer could accomplish the same thing by asking a specific set of open-ended questions during user interviews or focus groups.

---
## Writing effective questions
There are two parts to every survey question, the question itself and the provided set of answers. Let’s examine what makes a questionnaire effective. (Hint: These heuristics are also perfect for writing interview questions.)

**The flow of questions should be logical and organized.** A good questionnaire does not change topics in a jarring manner. If you ask people about the experience of using a medical device, don’t ask them who their favorite author is. The [priming effect](https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100345687?rskey=56jXHI&result=1) can also be a factor in the order of questions. This effect occurs when a previous question influences a participant’s answer. 

**Each question should be limited to a single concept.** If you ask about more than one concept, it’s unclear which one the participant responds to. “How many times have you eaten junk food or fast food in the last week?” is unclear about which item (junk food, fast food) they should answer. Additionally, the definition of both of those items is not universal. 

**Each question should be easy to understand.** Questions with ambiguous meaning or multiple interpretations will result in wrong answers. Remember, your job is to minimize the risk of someone answering incorrectly. Also, if it’s appropriate, _use a conversational tone_ to keep the participant engaged in the questions. Avoid double-negatives, unfamiliar jargon, and abbreviations. 

---
## Writing an answer set
 **The answer set should be relatively small.** People have a tough time remembering more than a few options. Unless you ask about an objective fact like what brand of vehicle they own, keep the answer list small. If you ask the questions aloud, the [recency effect](https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100407678) may cause participants to choose items heard later in a list. That is why it is best practice to randomize the options list to ensure they are not in the same order for each person. 

**The answer set should include all reasonable responses.** If you are asking about an objective fact, let’s say what pet you own, then it would be appropriate to have more than just a cat and dog in the answer set. 

**Include an opt-out option in an answer set.** In the example above, an opt-out response would be “I don’t have a pet” or “Does not apply.” If you don’t include this option, you are forcing the participant to choose an answer that is not true. 

**Balance answers when using a scale.** For example, *very bad*, *bad*, *neutral*, *good*, *very good* is a balanced answer set. The gap between *bad* and *neutral* and between *neutral* and *good* is easily understood as equal. It’s also an **ordinal scale** because the order of options is significant. 

Answer set: *extremely disappointed, disappointed, kind of disappointed, not at all disappointed, neutral.*
-   **The scale is not balanced.** The distance between *extremely disappointed* and *disappointed* does not appear to be the same as the distance between *not at all disappointed* and *neutral*.
-   **The scale is not ordinal.** It tries to measure the attitude towards a subject from worse to progressively better, but the difference between *not at all disappointed* and *neutral* is unclear. 
Better answer set: *extremely disappointed, somewhat disappointed, doesn’t bother me, somewhat happy, extremely happy. *

 **Neutral is a valid answer.** When you use an odd-numbered scale (Likert-type), it measures positive or negative responses. Neutral as the middle option gives your scale symmetry with equal negative and positive choices. It doesn’t force the participant to make up a feeling one way or the other if it doesn’t apply to them. 
-   Likert-type scales typically have 5, 7, or 9 options. You can measure nuance with more options, but make sure you require that nuance level before using a 7 or 9 point scale.

---

# Quiz: Effective Surveys
1. True or False: Close-ended questions can yield quantitative or qualitative data.
	1. True (correct)
	2. False
2. Fill in the blank: Survey questions should avoid _____.
	1. a sudden and unexpected change of topic.
	2. ambiguous meaning or unfamiliar jargon. 
	3. multiple concepts or two questions in one.
	4. all of the above. (correct)
3. Why should you randomize you answer sets?
	1. It provides a more balanced scale. 
	2. You don't want particpants sharing the answers with one another. 
	3. Partipants may be biased towards the last item they heard or read. (correct)
	4. Because Likert-type answers are always randomized.
4. True or False: A balanced, ordinal answer set does not need the same number of positive and negative answers as long as it includes *neutral* as the midpoint answer. 
	1. True
	2. False (correct)
5. Choose the category in the answer set that is not distinct enough from the other answers: *extremely bad, pretty bad, bad, neutral, good, extremely good*.
	1. neutral
	2. extremely good
	3. bad
	4. pretty bad (correct)
	5. good

---